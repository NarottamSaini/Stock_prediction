{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Time_Series_From__colab_v5-single fiunction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SOXET9T4x_Qb",
        "colab": {}
      },
      "source": [
        "# Recurrent Neural Network\n",
        "\n",
        "# Importing a data -> Selecting data/cols for training\n",
        "# training data feature scaling\n",
        "# Creata a list with each index having list of 60 values and o/p with one value (X_train, y_train)\n",
        "# Convert them into a array\n",
        "# Reshaping them into format required by RNN\n",
        "\n",
        "# building a RNN network\n",
        "# initializing RNN\n",
        "# adding a hidden layers\n",
        "# Compiling a RNN\n",
        "# fitting RNN for training on train set\n",
        "\n",
        "# import the test_data set -> selecting a req. column from a main dataframe\n",
        "# creating a 'input' variable from df which will take last 60 values from training set from which it will predict first value of o/p\n",
        "# reshape and transform the variable\n",
        "\n",
        "# prepare the x_test with last 60 value of x_train \n",
        "# np.array, reshape \n",
        "# using .predict for predicting \n",
        "\n",
        "\n",
        "# Part 1 - Importing libararies and data files\n",
        "\n",
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Waznr5V1H3jz",
        "colab_type": "code",
        "outputId": "24add557-288a-4785-8496-d609ca7a0804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# file path - /content/1.csv\n",
        "import glob\n",
        "\n",
        "path = r'/content/' # use your path\n",
        "all_files = glob.glob(path + \"/*.csv\")\n",
        "all_files = list(all_files)\n",
        "print(all_files[0:3])\n",
        "#file_names = all_files.replace('/content/','')\n",
        "file_name = []\n",
        "for y in all_files:\n",
        "  file_list = (y.strip('/content/'))\n",
        "  file_name.append(file_list)\n",
        "\n",
        "print(file_name)\n",
        "\n",
        "#print(file_name[0],file_name[1],file_name[2],file_name[3])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/81.csv', '/content/80.csv']\n",
            "['81.csv', '80.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4pcaZ_Jsx_Qg",
        "colab": {}
      },
      "source": [
        "def file_processing(filename):  \n",
        "  \n",
        "  print(' Importing the training set :\\n')\n",
        "  print('file getting processed inside function:',filename)\n",
        "\n",
        "  df = pd.read_csv(filename)\n",
        "\n",
        "  row_count = round((len(df)-30))\n",
        "  print('row_count :', row_count)\n",
        "\n",
        "  dataset_train = df.iloc[:row_count, 4:5]\n",
        "  training_set = dataset_train.values\n",
        "\n",
        "  # n_steps = 60\n",
        "  n_features = 1\n",
        "\n",
        "  # print(training_set.dtype)\n",
        "  # print(training_set[0:5])\n",
        "  print('len(df)',len(df))\n",
        "  print('len(training_set)',len(training_set))\n",
        "  # print(len(dataset_train))\n",
        "\n",
        "  print('######  Feature Scaling : ######\\n')\n",
        "\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  sc = MinMaxScaler(feature_range = (0, 1))\n",
        "  training_set_scaled = sc.fit_transform(training_set)\n",
        "  print(len(training_set_scaled))\n",
        "\n",
        "  # Creating a data structure with 60 timesteps and 1 output\n",
        "  print('######  Creating a data structure with 60 timesteps and 1 output : ######\\n')\n",
        "\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  for i in range(60, len(training_set_scaled)):\n",
        "      X_train.append(training_set_scaled[i-60:i, 0])\n",
        "      y_train.append(training_set_scaled[i, 0])\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "  # Reshaping\n",
        "  print('######  Reshaping : ######\\n')\n",
        "\n",
        "  X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "  # print('X_train.shape nparray:', X_train.shape)\n",
        "  # print('(X_train[0:1] np.array :\\n', len(X_train[0:1]))\n",
        "  # print('X_train.shape[0] :', X_train.shape[0])\n",
        "  # print('X_train.shape[1] :', X_train.shape[1])\n",
        "  # print('X_train.shape[2] :', X_train.shape[2])\n",
        "\n",
        "  # Part 2 - Building the RNN\n",
        "  print('###### Part 2 - Building the RNN : ###### \\n')\n",
        "\n",
        "  # Importing the Keras libraries and packages\n",
        "  from keras.models import Sequential\n",
        "  from keras.layers import Dense\n",
        "  from keras.layers import LSTM\n",
        "  from keras.layers import Dropout\n",
        "\n",
        "  # Initialising the RNN\n",
        "  model = Sequential()\n",
        "\n",
        "  # Stacked LSTM\n",
        "  # Multiple hidden LSTM layers can be stacked one on top of another in what is referred to as a Stacked LSTM model.\n",
        "  # An LSTM layer requires a three-dimensional input and LSTMs by default will produce a two-dimensional output as an interpretation from the end of the sequence.\n",
        "  # We can address this by having the LSTM output a value for each time step in the input data by setting the return_sequences=True argument on the layer. This allows us to have 3D output from hidden LSTM layer as input to the next.\n",
        "\n",
        "  # Adding the first LSTM layer and some Dropout regularisation\n",
        "  model.add(LSTM(units = 200, return_sequences = True, input_shape = (X_train.shape[1], n_features),activation='relu')) # input_shape=(n_steps, n_features)\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Adding a second LSTM layer and some Dropout regularisation\n",
        "  model.add(LSTM(units = 200, return_sequences = True)) # activation='relu' at each LSTM layers\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Adding a third LSTM layer and some Dropout regularisation\n",
        "  model.add(LSTM(units = 200, return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Adding a Extra LSTM layer and some Dropout regularisation\n",
        "  model.add(LSTM(units = 100, return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "  # Adding a fourth LSTM layer and some Dropout regularisation\n",
        "  model.add(LSTM(units = 100))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  # Adding the output layer\n",
        "  model.add(Dense(units = 1,activation='relu'))\n",
        "\n",
        "  # Compiling the RNN\n",
        "  #model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics= ['mean_squared_error'])\n",
        "\n",
        "\n",
        "  # Fitting the RNN to the Training set\n",
        "  model.fit(X_train, y_train, epochs = 100, batch_size = 512)\n",
        "\n",
        "  # Part 3 - Making the predictions and visualising the results\n",
        "  print('####### Part 3 - Making the predictions and visualising the results ####### \\n')\n",
        "  # Getting the real stock price of test data\n",
        "  #dataset_test = pd.read_csv('Test_data_1.csv')\n",
        "  dataset_test = df.iloc[row_count:,4:5]\n",
        "  real_stock_price = dataset_test.values\n",
        "\n",
        "  # Getting the predicted stock price of test data\n",
        "\n",
        "  print('####### Getting the predicted stock price of test data ###### \\n')\n",
        "  dataset_total = pd.concat((dataset_train['close'], dataset_test['close']), axis = 0)\n",
        "  inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "  print('inputs values', len(inputs))\n",
        "  print('inputs shape', inputs.shape)\n",
        "\n",
        "  inputs = inputs.reshape(-1,1)\n",
        "  # print('inputs reshape', len(inputs))\n",
        "  print('inputs reshape', inputs.shape)\n",
        "  # print('dataset_total :', len(dataset_total))\n",
        "\n",
        "  inputs = sc.transform(inputs)\n",
        "  # print('inputs transform', len(inputs))\n",
        "  print('inputs transform', inputs.shape)\n",
        "\n",
        "\n",
        "  print('####### Model Prediction ####### \\n')\n",
        "  X_test = []\n",
        "  for i in range(60, len(dataset_test)+60):\n",
        "      X_test.append(inputs[i-60:i, 0])\n",
        "\n",
        "  #print('(X_test[0:3] :\\n', X_test[0:3])\n",
        "  print('len of X_test', len(X_test))\n",
        "  print('len of [X_test 0]:', len(X_test[0]))\n",
        "\n",
        "  print('(X_test[0:1] :\\n', X_test[0:1])\n",
        "\n",
        "  X_test = np.array(X_test)\n",
        "  # print('X_test.shape nparray:', X_test.shape)\n",
        "  # print('(X_test[0:1] np.array :\\n', X_test[0:1])\n",
        "\n",
        "  # print('X_test.shape[0] :', X_test.shape[0])\n",
        "  # print('X_test.shape[1] :', X_test.shape[1])\n",
        "  # print('X_test.shape[1] :', X_test.shape[2])\n",
        "\n",
        "  # The model expects the input shape to be three-dimensional with [samples, timesteps, features]\n",
        "  X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "  print('X_test reshape:', len(X_test))\n",
        "\n",
        "  predicted_stock_price = model.predict(X_test)\n",
        "  predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
        "\n",
        "\n",
        "  # Visualising the results\n",
        "  print('###### Visualising the results ######\\n')\n",
        "\n",
        "  plt.plot(real_stock_price, color = 'red', label = 'Real Stock Price')\n",
        "  plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted  Stock Price')\n",
        "  plt.title('Stock Price Prediction')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Stock Price')\n",
        "  plt.legend()\n",
        "  mse_chart =  (f'{filename}_MeanSquareError.png')\n",
        "  print('Name of .png file mse_chart', mse_chart)\n",
        "  plt.savefig(mse_chart)\n",
        "  plt.show()\n",
        "\n",
        "  ## Model summary\n",
        "  print('dataset_train.info()', dataset_train.info())\n",
        "  print('dataset_test.info()', dataset_test.info())\n",
        "  model.summary()\n",
        "  #print('model_list,model_summary', model_list,model_summary)\n",
        "  #return model_list,model_summary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R9kK_MECx_Qj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "c034cb56-6af5-43ef-b6ca-d855d83f5a81"
      },
      "source": [
        "for i in range(len(file_name)):\n",
        "  #filename = all_files[i]\n",
        "  csv_file = file_name[i]\n",
        "  print('file getting processed :',file_name[i])\n",
        "  #model_list,model_summary = file_processing(file_name[i])\n",
        "  file_processing(file_name[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file getting processed : 81.csv\n",
            " Importing the training set :\n",
            "\n",
            "file getting processed inside function: 81.csv\n",
            "row_count : 5620\n",
            "len(df) 5650\n",
            "len(training_set) 5620\n",
            "######  Feature Scaling : ######\n",
            "\n",
            "5620\n",
            "######  Creating a data structure with 60 timesteps and 1 output : ######\n",
            "\n",
            "######  Reshaping : ######\n",
            "\n",
            "###### Part 2 - Building the RNN : ###### \n",
            "\n",
            "Epoch 1/100\n",
            "5560/5560 [==============================] - 78s 14ms/step - loss: 0.0262 - mean_squared_error: 0.0262\n",
            "Epoch 2/100\n",
            "5560/5560 [==============================] - 64s 11ms/step - loss: 0.0051 - mean_squared_error: 0.0051\n",
            "Epoch 3/100\n",
            "5560/5560 [==============================] - 64s 12ms/step - loss: 0.0029 - mean_squared_error: 0.0029\n",
            "Epoch 4/100\n",
            "5560/5560 [==============================] - 64s 12ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n",
            "Epoch 5/100\n",
            "5560/5560 [==============================] - 63s 11ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 6/100\n",
            "5560/5560 [==============================] - 63s 11ms/step - loss: 0.0017 - mean_squared_error: 0.0017\n",
            "Epoch 7/100\n",
            "5560/5560 [==============================] - 62s 11ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 8/100\n",
            "5560/5560 [==============================] - 64s 12ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 9/100\n",
            "5560/5560 [==============================] - 64s 12ms/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
            "Epoch 10/100\n",
            "5560/5560 [==============================] - 64s 11ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 11/100\n",
            "5560/5560 [==============================] - 65s 12ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 12/100\n",
            "5560/5560 [==============================] - 64s 11ms/step - loss: 0.0015 - mean_squared_error: 0.0015\n",
            "Epoch 13/100\n",
            "5560/5560 [==============================] - 64s 11ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 14/100\n",
            "5560/5560 [==============================] - 65s 12ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 15/100\n",
            "5560/5560 [==============================] - 63s 11ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 16/100\n",
            "5560/5560 [==============================] - 65s 12ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 17/100\n",
            "5560/5560 [==============================] - 63s 11ms/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
            "Epoch 18/100\n",
            "5560/5560 [==============================] - 65s 12ms/step - loss: 0.0013 - mean_squared_error: 0.0013\n",
            "Epoch 19/100\n",
            "2560/5560 [============>.................] - ETA: 35s - loss: 0.0012 - mean_squared_error: 0.0012"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iFjUxu1ox_Qm",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4BjjVAJcx_Qp",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_JrwHvryx_Qr",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x-BAiI2fx_Qu",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k5yRoNO-x_Qw",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLtmKrVgRs0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVXDNWHix_Qy",
        "colab": {}
      },
      "source": [
        "#  for l in ([1,2,31,67]):\n",
        "#   mse_chart =  (f'{l}_MeanSquareError.png')\n",
        "#   print('Name of .png file mse_chart', mse_chart)\n",
        "#   #plt.savefig(mse_chart)\n",
        "#   #plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJ_sni_dx_Q0",
        "colab": {}
      },
      "source": [
        "# print(len(predicted_stock_price))\n",
        "# print(predicted_stock_price[0:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omwFY4hc2AsV",
        "colab": {}
      },
      "source": [
        "# len(dataset_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_YBjAfgmxIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df['Predicted Price'] = np.NAN\n",
        "# print(df['Predicted Price'].shape)\n",
        "# df.iloc[row_count:,6] = predicted_stock_price\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bj9wLkjL8N7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.to_csv('Predicted stock price.csv')\n",
        "# #print(df.head(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44TNo6eUPsJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R6foTbw11YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Step 8: Evaluate model\n",
        "# scores = model.evaluate(X_test, predicted_stock_price)\n",
        "# print(\"Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9lZGT5wfEFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import numpy as np\n",
        "# y = np.zeros((2,3,4))\n",
        "# print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJuwW_cpl48M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(y.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O00fOB8emGHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y = y.reshape(8,3)\n",
        "# print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDhKBDrnmNJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}